# Southwest Airlines: OTP and Load Factor Analysis

## Project Overview

This project analyzes the relationship between Southwest Airlines' On-Time Performance (OTP) and Load Factor (capacity utilization) on their top 5 domestic routes from January 2020 through June 2025.

**Research Question:** How does Southwest's OTP relate to the Load Factor of its flights on the top 5 domestic routes?

## Project Structure

```
project/
│
├── data/
│   ├── raw/
│   │   ├── OTP_Data/              # Monthly OTP CSV files
│   │   │   └── AUG_2021_OTP_SEGMENT.csv
│   │   │   └── [other monthly files...]
│   │   │
│   │   └── Load_Factor_Data/      # Annual Load Factor CSV files
│   │       └── 2020_Segment.csv
│   │       └── 2021_Segment.csv
│   │       └── 2022_Segment.csv
│   │       └── 2023_Segment.csv
│   │       └── 2024_Segment.csv
│   │       └── 2025_Segment.csv
│   │
│   └── processed/                  # Cleaned and processed data (not tracked in git)
│       └── .gitkeep                # Ensures directory is present in repo
│       └── lf_clean_southwest.csv  # Generated by analysis, not tracked in git
│       └── otp_clean_southwest.csv
│       └── lf_top5_routes.csv
│       └── otp_top5_routes.csv
│       └── top5_routes.csv
│       └── merged_lf_otp_top5.csv
│       └── route_summary_statistics.csv
│
├── notebooks/
│   ├── 01_data_exploration.ipynb      # Initial data exploration
│   ├── 02_route_analysis.ipynb        # Top routes identification
│   └── 03_otp_loadfactor_analysis.ipynb  # Main correlation analysis
│
├── src/
│   ├── __init__.py                # Package initialization
│   ├── data_loader.py             # Data loading utilities
│   ├── data_cleaner.py            # Data cleaning functions
│   └── metrics.py                 # Metrics calculation
│
├── reports/
│   └── final_report.md            # Final analysis report
│   └── final_report_completed.md   # Auto-generated final report (Markdown)
│   └── final_report_completed.ipynb # Auto-generated final report (Notebook, Markdown cells)
│
├── requirements.txt               # Python dependencies
├── README.md                      # Main project documentation: overview, setup usage, troubleshooting and references
├── project_summary.md             # High-level summary of project structure, data flow, and analysis steps
├── run_analysis.py                # Script to run the entire analysis pipeline and generate all processed data automatically
└── .gitignore                     # Git ignore rules
```

## Final Report Files

After completing your analysis, you can use either of the following for your final report:
- `reports/final_report_completed.md` (Markdown file)
- `reports/final_report_completed.ipynb` (Notebook version with markdown cells)

To generate or update the final report, run:

```bash
python generate_report.py
```

This will create or update both report files in the `reports/` directory.

**Tip:** The `.ipynb` version is ideal for sharing or further editing in Jupyter, while the `.md` version is easy to view or print as plain text. Both contain the same content.

## Data Sources

### 1. Load Factor Data (T-100 Domestic Segment)
- **Source:** U.S. Bureau of Transportation Statistics (BTS)
- **Format:** Annual CSV files
- **Period:** 2020-2025
- **Key Fields:**
  - CARRIER: Airline code
  - ORIGIN, DEST: Airport codes
  - PASSENGERS: Total passengers
  - SEATS: Available seats
  - DEPARTURES_PERFORMED: Actual flights
  - YEAR, MONTH: Time period

### 2. On-Time Performance Data
- **Source:** U.S. Bureau of Transportation Statistics (BTS)
- **Format:** Monthly CSV files
- **Period:** January 2020 - June 2025
- **Key Fields:**
  - OP_UNIQUE_CARRIER: Airline code
  - ORIGIN, DEST: Airport codes
  - DEP_DEL15: Departure delay indicator
  - ARR_DEL15: Arrival delay indicator
  - CANCELLED: Cancellation indicator
  - CARRIER_DELAY, WEATHER_DELAY, etc.: Delay reasons
  - YEAR, MONTH: Time period

## Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager
- Jupyter Notebook or JupyterLab

### Setup Instructions

1. **Clone or download this project**

2. **Create a virtual environment (recommended):**
   ```bash
   python -m venv venv
   
   # On Windows:
   venv\Scripts\activate
   
   # On macOS/Linux:
   source venv/bin/activate
   ```

3. **Install required packages:**
   ```bash
   pip install -r requirements.txt
   ```


4. **Prepare your data:**
   - No action needed! All required raw CSV files are already included in the repository under `data/raw/` when you clone or download the project.


   # Note: The `data/processed/` directory is created automatically by the analysis scripts/notebooks. A `.gitkeep` file ensures the directory is present in the repo, but processed data files are not tracked by git (see `.gitignore`).

## Usage


### Running the Analysis

You can run the analysis in two ways:

**Option 1: Automated Script (Fastest)**
```bash
python run_analysis.py
```
This will generate all processed data and statistics in `data/processed/`.

**Option 2: Jupyter Notebooks (Most Interactive)**
```bash
jupyter notebook
# Then run notebooks 01, 02, 03 in order
```
Each notebook will save outputs to `data/processed/` as you go.

**Note:** The `data/processed/` directory is always present in the repo (due to `.gitkeep`), but the processed data files themselves are not tracked by git due to `.gitignore` rules.
## .gitignore and .gitkeep

The `.gitignore` is set up to ignore all files in `data/processed/` except `.gitkeep`. This ensures the directory is always present in the repo, but large processed data files are not tracked. You must generate these files yourself by running the analysis.

### Using the Python Modules

You can also use the modules directly in your own scripts:

```python
from src import DataLoader, DataCleaner, MetricsCalculator

# Load data
loader = DataLoader(base_path='data/raw')
lf_raw, otp_raw = loader.load_all_data()

# Clean data
cleaner = DataCleaner(carrier_code='WN')
lf_clean = cleaner.clean_load_factor_data(lf_raw)
otp_clean = cleaner.clean_otp_data(otp_raw)

# Calculate metrics
calc = MetricsCalculator()
merged = calc.merge_lf_otp_by_route_month(lf_clean, otp_clean)
correlation = calc.calculate_correlation(merged, 'LOAD_FACTOR', 'DEP_ONTIME_PCT')
```

## Key Metrics

### Load Factor
- **Definition:** (Passengers / Available Seats) × 100
- **Interpretation:** Percentage of seats filled
- **Industry Context:** Higher is better for revenue, but may impact operations

### On-Time Performance (OTP)
- **Departure OTP:** % of flights departing within 15 minutes of schedule
- **Arrival OTP:** % of flights arriving within 15 minutes of schedule
- **Industry Standard:** FAA considers ≤15 minutes as "on-time"

### Correlation Analysis
- **Pearson r:** Measures linear relationship strength (-1 to +1)
- **Spearman ρ:** Measures monotonic relationship (non-parametric)
- **p-value:** Statistical significance (typically p < 0.05)

## Expected Results

The analysis will produce:

1. **Data Files:**
   - Cleaned Southwest-only datasets
   - Top 5 routes filtered data
   - Merged monthly route-level metrics
   - Summary statistics by route

2. **Visualizations:**
   - Time series plots of load factor and OTP trends
   - Scatter plots showing LF-OTP relationships
   - Correlation heatmaps
   - OTP by load factor bin charts
   - Route-specific detailed analyses

3. **Statistical Results:**
   - Correlation coefficients and significance tests
   - Route-by-route summary statistics
   - Load factor threshold analysis
   - Temporal pattern identification

4. **Final Report:**
   - Comprehensive markdown report with findings
   - Business implications and recommendations
   - Visualizations and statistical evidence

## Key Findings (To Be Completed)

After running the analysis, key findings will include:
- Overall correlation between load factor and OTP
- Route-specific patterns and variations
- Load factor thresholds where OTP changes
- COVID-19 impact and recovery trends
- Business implications for capacity planning

## Troubleshooting

### Common Issues

**Issue:** `FileNotFoundError` when loading data
- **Solution:** Check that CSV files are in the correct directories
- **Solution:** Verify file naming conventions match expected patterns

**Issue:** Missing values or data quality warnings
- **Solution:** Review the data cleaning steps in the notebooks
- **Solution:** Check source data for completeness

**Issue:** Import errors for `src` modules
- **Solution:** Ensure you're running notebooks from the project root
- **Solution:** Add parent directory to path: `sys.path.append('..')`

**Issue:** Correlation calculations returning NaN
- **Solution:** Check that routes have sufficient data points (N > 2)
- **Solution:** Verify date ranges overlap between LF and OTP data

## Contributing

To extend this analysis:

1. **Add more carriers:** Modify `carrier_code` in DataCleaner
2. **Analyze different routes:** Change `n` parameter in `get_top_routes()`
3. **Different time periods:** Adjust date filters in `filter_date_range()`
4. **Additional metrics:** Extend MetricsCalculator class
5. **New visualizations:** Add cells to notebooks or create new notebooks

## License

This project uses publicly available data from the U.S. Bureau of Transportation Statistics.
## License

This project is licensed under the MIT License.

```
MIT License

Copyright (c) 2025 jQueryousGeorge

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

## References

- [BTS T-100 Domestic Segment Data](https://www.transtats.bts.gov/Tables.asp?QO_VQ=EFD&QO_anzr=Nv4%20Pn44vr4f%20g100%20Frtrzrag%20)
- [BTS On-Time Performance Data](https://www.transtats.bts.gov/Tables.asp?QO_VQ=EFD&QO_anzr=Nv4yv0r%20b0-gvzr%20cr4s14zn0